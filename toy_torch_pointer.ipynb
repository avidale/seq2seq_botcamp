{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве тренировки делаю сетку, которая кодирует входную последовательность $x$ и последовательности $y_1...y_k$, и выбирает такой из игреков, представление которого было бы максимально похоже на представление $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ToyChooser(nn.Module):\n",
    "    def __init__(self, hidden_size=64, vocab_size=14, embedding_dim=32, proj_size=128):\n",
    "        super().__init__()\n",
    "        RNN = nn.LSTM\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.sent_rnn = RNN(embedding_dim, hidden_size, bidirectional=True)\n",
    "        self.sent_proj = nn.Linear(hidden_size * 2, proj_size)\n",
    "        \n",
    "        self.option_rnn = RNN(embedding_dim, hidden_size, bidirectional=True)\n",
    "        self.option_proj = nn.Linear(hidden_size * 2, proj_size)\n",
    "        \n",
    "        self.mix_mlp = nn.Sequential(\n",
    "            nn.Linear(3 * proj_size, proj_size), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(proj_size, 1),             \n",
    "        )\n",
    "    \n",
    "    def forward(self, sentence, options):\n",
    "        batch_size = 1\n",
    "        sent_len = sentence.shape[0]\n",
    "        x = self.embeddings(sentence).view(sent_len, batch_size,  -1)\n",
    "        sent_rnn_out, _ = self.sent_rnn(x)\n",
    "        encoded_sentence = self.sent_proj(sent_rnn_out[-1])[0]\n",
    "        \n",
    "        dots = []\n",
    "        for option in options:\n",
    "            z = self.embeddings(option).view(option.shape[0], batch_size,  -1)\n",
    "            opt_rnn_out, _ = self.option_rnn(z)\n",
    "            encoded_option = self.option_proj(opt_rnn_out[-1])[0]\n",
    "            #dots.append(torch.cosine_similarity(encoded_sentence, encoded_option, dim=0))\n",
    "            dots.append(self.mix_mlp(\n",
    "                torch.cat([encoded_sentence, encoded_option, torch.mul(encoded_sentence, encoded_option)])\n",
    "            ))\n",
    "        \n",
    "        return torch.stack(dots).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ToyChooser()\n",
    "xx = torch.tensor([1, 2, 3])\n",
    "model.embeddings(xx).view(1, 3,  -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0284, 0.0528, 0.0423]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([1, 2, 3]), torch.tensor([[1,2],[3,4],[5,6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала научу мою модельку выбирать из четырехзначных чисел такое, которое давало бы 10000 в сумме с моим числом. \n",
    "\n",
    "Учится очень быстро (хотя числа написаны цифрами)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def to_digits(number, max_len=2, pad=11, first=12, last=13):\n",
    "    digits = [int(x) for x in str(number)]\n",
    "    while len(digits) < max_len:\n",
    "        digits.append(pad)\n",
    "    return torch.tensor([first] + digits + [last])\n",
    "\n",
    "def make_example(min_options=2, max_options=5, total=99):\n",
    "    x = random.randint(0, total)\n",
    "    y = total - x\n",
    "    n_options = random.randint(min_options, max_options)\n",
    "    options = [y] + [random.randint(0, total) for i in range(n_options - 1)]\n",
    "    options = [to_digits(z) for z in options]\n",
    "    return to_digits(x), options, torch.tensor([0]) #torch.tensor([1] + [0] * (n_options - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12,  4,  4, 13]),\n",
       " [tensor([12,  5,  5, 13]),\n",
       "  tensor([12,  1,  7, 13]),\n",
       "  tensor([12,  2,  9, 13])],\n",
       " tensor([0]))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = make_example()\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0414, 0.0387, 0.0397]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model(e[0], e[1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0971, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(scores, torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моделька учится быстро и для двухзначных, и для четырехзначных чисел, хотя для четырехзначных точность довольно долго не уходит в 100%. Видимо, сначала моделька долго хитрит и использует только самые правые цифры, что иногда её подводит.\n",
    "\n",
    "Если увеличить число негативов, перформанс должен вырасти, правда, сравнивать точность надо на батчах с одним и тем же числом негативов, это немножко влом. \n",
    "\n",
    "Если сравнивать не косинусную близость, а просто скоры какой-то линейной сетки, то лосс падает быстрее, но, кажется, точность увеличивается не столь драматично. Если в эту линейную сетку добавить покоординатные произведения эмбеддингов, сходимость здорово ускоряется; сеточка оптимизируется очень уверенно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7480559253692627 0.27\n",
      "1.6768263405561448 0.23\n",
      "1.7160321789979935 0.17\n",
      "1.626733974814415 0.27\n",
      "1.6945529627799987 0.3\n",
      "1.7257419884204865 0.31\n",
      "1.6590426933765412 0.31\n",
      "1.6574965995550155 0.36\n",
      "1.5925902646780015 0.44\n",
      "1.31816881865263 0.47\n",
      "1.215805449783802 0.44\n",
      "1.1921605312824248 0.52\n",
      "0.9778940753638744 0.7\n",
      "0.9012304529547691 0.59\n",
      "0.9613528645038605 0.57\n",
      "0.9437034785747528 0.63\n",
      "0.7360621747374535 0.7\n",
      "0.7954510005563498 0.7\n",
      "0.8864778475463391 0.55\n",
      "0.7615344820916653 0.63\n",
      "0.8549534755945206 0.67\n",
      "0.7611990250647068 0.69\n",
      "0.7477109287679196 0.66\n",
      "0.7019262601062656 0.69\n",
      "0.6603471165150404 0.72\n",
      "0.7465430384129286 0.65\n",
      "0.7170129759609699 0.72\n",
      "0.640943868663162 0.72\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-332-c7f523a84111>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ddale\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ddale\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PRINT_EVERY = 100\n",
    "\n",
    "it = 0\n",
    "tot = 0\n",
    "act = 0\n",
    "\n",
    "while True:\n",
    "    x, z, y = make_example(total=10000, max_options=10)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    scores = model(x, z)\n",
    "    l = loss_function(scores, y)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    it += 1\n",
    "    tot += l.item()\n",
    "    act += (scores.detach().numpy().argmax() == 0)\n",
    "    if it == PRINT_EVERY:\n",
    "        print(tot/it, act/it)\n",
    "        it = 0\n",
    "        tot = 0\n",
    "        act = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToyChooser(\n",
      "  (embeddings): Embedding(14, 32)\n",
      "  (sent_rnn): LSTM(32, 64, bidirectional=True)\n",
      "  (sent_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (option_rnn): LSTM(32, 64, bidirectional=True)\n",
      "  (option_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (mix_mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
